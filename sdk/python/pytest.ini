[pytest]
# Pytest configuration for Vauntico Python SDK
# Enterprise-grade testing setup with comprehensive coverage reporting

# Test discovery
testpaths = tests
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*
addopts = 
    --strict-markers
    --strict-config
    --verbose
    --tb=short
    --cov=vauntico_sdk
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml
    --cov-report=json:coverage.json
    --cov-report=lcov
    --cov-fail-under=80
    --junit-xml=junit.xml
    --maxfail=10
    --durations=10
    --color=yes

# Coverage configuration
[coverage:run]
source = src/vauntico_sdk
omit = 
    */tests/*
    */test_*
    */*_test.py
    */__pycache__/*
    */.pytest_cache/*
    */venv/*
    */.venv/*
    */dist/*
    */build/*
    */.tox/*
    */migrations/*
    */conftest.py
    */setup.py
    */conftest.py
    */fixtures/*
    */factories/*
    */mocks/*

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    if self.debug:
    if settings.DEBUG
    raise AssertionError
    raise NotImplementedError
    if 0:
    if __name__ == .__main__.:
    class .*\bProtocol\):
    @(abc\.)?abstractmethod
    @overload
    @typing.overload
    # Type checking
    if TYPE_CHECKING:
    # Development only
    if False:
    # Error handling that won't be tested
    except ImportError:
    except ModuleNotFoundError:

precision = 2
show_missing = true
skip_covered = false
skip_empty = true

[coverage:html]
directory = htmlcov
title = Vauntico Python SDK Coverage Report

[coverage:xml]
output = coverage.xml

[coverage:json]
output = coverage.json

[coverage:lcov]
output = coverage.lcov

# Markers
markers =
    # Test type markers
    unit: Unit tests (fast, isolated)
    integration: Integration tests (slow, external dependencies)
    e2e: End-to-end tests (very slow, full system)
    
    # Component markers
    auth: Authentication related tests
    api: API integration tests
    client: Client library tests
    types: Type validation tests
    models: Model tests
    
    # Speed markers
    slow: Marks tests as slow (deselect with '-m "not slow"')
    fast: Marks tests as fast (default)
    
    # Environment markers
    local: Tests that run locally
    ci: Tests that run in CI
    production: Production environment tests
    
    # External dependency markers
    network: Tests that require network access
    database: Tests that require database
    external_api: Tests that hit external APIs
    
    # Feature flags
    enterprise: Enterprise feature tests
    beta: Beta feature tests
    experimental: Experimental feature tests
    
    # Quality markers
    flaky: Known flaky tests (may fail intermittently)
    smoke: Smoke tests (basic functionality)
    regression: Regression tests
    
    # Security markers
    security: Security-related tests
    vuln: Vulnerability tests
    
    # Performance markers
    performance: Performance tests
    load: Load tests
    
    # Platform markers
    linux_only: Tests that only run on Linux
    windows_only: Tests that only run on Windows
    macos_only: Tests that only run on macOS

# Logging configuration
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(filename)s:%(lineno)d %(funcName)s(): %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Filter configuration
filterwarnings =
    ignore::UserWarning
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    error::ResourceWarning
    default::pytest.PytestUnraisableWarning
    default::pytest.PytestUnhandledThreadExceptionWarning

# Timeout configuration
timeout = 300
timeout_method = thread

# Parallel execution
addopts = -n auto

# Minimum version requirements
minversion = 7.0

# Console output
console_output_style = progress
console_output_switch = STDOUT

# JUnit XML configuration
junit_family = xunit2
junit_logging = all

# Test session configuration
consider_namespace_packages = true
importmode = importlib

# Cache configuration
cache_dir = .pytest_cache

# Doctest configuration
doctest_optionflags = NORMALIZE_WHITESPACE ELLIPSIS
doctest_continue_on_failure = true

# Mock configuration
mock_use_standalone_module = false

# Assert configuration
faulthandler_timeout = 0.5

# XFAIL configuration
xfail_strict = true

# Catch configuration
catch_break = true
catch_log_exceptions = true
catch_log_global = true
catch_log_level = WARNING

# Benchmark configuration
benchmark_only = false
benchmark_sort = min
benchmark_columns = min, max, mean, stddev, median, rounds, iterations
benchmark_histogram = true
benchmark_save = data.json
benchmark_save_data = true

# Mypy integration (if installed)
mypy = false
mypy_ignore_missing_imports = true

# Performance profiling
profile = none

# Continuous Integration settings
# Override these in CI with environment variables
# PYTEST_ADDOPTS = --cov-report=xml --junit-xml=junit.xml

# Enterprise-specific settings
# Enable for stricter testing in production environments
# PYTEST_STRICT = true

# Test data configuration
test_data_path = tests/fixtures
test_config_path = tests/config

# API testing configuration
api_base_url = https://api.vauntico.com/v1
api_timeout = 30
api_retries = 3

# Authentication testing
test_api_key = test_api_key_12345
test_jwt_token = test_jwt_token_abcdef
test_user_id = test_user_12345
test_organization_id = test_org_67890
